\documentclass{article}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{authblk}
\usepackage{amssymb}
\usepackage{float}
\usepackage{xurl}

\begin{document}

  \title{Project in Advanced Multiprocessor Programming}
  \author[1]{Aleksei Karasev - 12227646}
  \author[2]{Mariana da Silva Barros - 12202389}
  \affil[1]{MSc student of Computer Engineering, TU Wien}
  \affil[2]{MSc student of Computer Engineering, TU Wien}

  \maketitle

  \section{Introduction}
  Priority queues serve as an important basic tool in algorithmic design.
  They are widely used in a variety of applications and systems, such as simulation systems, job scheduling (in computer systems), networking (e.g., routing and real-time bandwidth management), file compression, numerical computations, and more. With the proliferation of modern parallel platforms, the need for a high-performance concurrent implementation of the priority queue has become acute.\par

  The basic structure of a priority queue (PQ) is a queue data structure that stores values in a particular order depending on the priority. Therefore, for each element stored in this structure, there is also a priority associated that can vary depending on the application. The abstract definition of a PQ provides a set of key-value pairs, where the key represents the priority.\par

  A PQ supports two operations: \textit{insert()} and \textit{deleteMin()}. The \textit{insert()} method inserts a new key-value pair into the set in the appropriate position (the keys don't have to be unique), and the \textit{deleteMin()} method removes and returns the value associated with the lowest key (i.e., highest priority) in the set.\par

  In this report, we present the design of a high-performance lock-free linearizable PQ called CBPQ, based on the paper [1].\par
  In a nutshell, as described in [1], CBPQ combines the following ideas:

  \begin{itemize}
    \item{It is used a chunked linked list as an underlying data structure, which allows to search for a chunk for insertion operation more efficiently.}
    \item{For threads concurrency, we apply synchronization primitives, such as critical sections and atomic operations (\textit{atomic or, atomic xor, atomic fetch and increment, atomic compare and swap}).}
  \end{itemize}

  The following section will provide a more detailed description of how CBPQ works.

  \section{Overview}
  \subsection{CBPQ Design}

  As previously mentioned, CBPQ is based on a chunked linked-list structure. In particular, the PQ initially contains three chunks to store values. Each chunk has an associated state, which describes which operation is being performed, or which operations are currently supported.\par

  The first chunk is structured in a particular way, because it stores the key-value pairs with the highest priority (key range $0 \leqslant 20$). Therefore, this is the only chunk that supports \textit{deleteMin()} operation, and it doesn't permit direct insertion. In order to insert elements into this first chunk, we use an associated buffer, which will be further discussed below.\par

  The remaining two chunks serve for insertion only, which is done directly in the chunk, without a buffer. The key ranges of the second and third chunks are $21 \leqslant 40$ and $41 \leqslant 4294967295$, respectively.\par
  Due to lack of space, we omit the concrete description of the chunk structure and its properties, which might be found in the paper our work is based on [1].\par

  We would like to briefly explain the \textit{insert()} and \textit{deleteMin()} operations usage, and look at several cases that might appear during queue exploitation.

  \paragraph{Insertion into the first chunk}\mbox{}\par

  Insertion into the first chunk may happen when its state is \emph{DELETION}, and we want to store a key-value pair with key range $0 \leqslant 20$.\par

  Initially, the correct chunk for insertion is searched in the queue. Right after the first chunk is found, \textit{insertToBuffer()} function is called in order to put the new element into the buffer. Inside this function, each thread checks whether or not one of the previous threads has already allocated the buffer. If it was, then the element is stored in the already existing buffer. Otherwise, the thread first allocates the buffer, and then stores the new item into it.\par

  Every time a new element is placed into the buffer, we must restructure the CBPQ to merge the current first chunk with its buffer. First of all, the chunks are marked as \emph{FROZEN} in the \textit{freezeChunk()} function. By doing this, we signalize to all other threads that this chunk is already in use, so the other threads don't try to use this chunk and cause a synchronization problem. Once the chunk is frozen, \textit{freezeRecovery()} function is called in order to restructure the CBPQ. In case of insertion into the first chunk, we execute \textit{mergeFirstChunk()} function, which merges the current first chunk with the buffer and returns a pointer to the new first chunk (which is now the actual first chunk in our queue).\par

  In the situation where the current first chunk is already full and doesn't have space for new elements from the buffer, several new \emph{DELETION} chunks are created. Also, there might be a case where it is impossible for a thread to put a new element into the buffer, due to the fact that the buffer is completely packed by other threads already. Then, the thread first restructures the queue, and then retries to store its element again.\par

  Once the new key-value pair is successfully added into the first chunk, the thread increases the index using an atomic F\&I instruction, and we can safely return.

  \paragraph{Insertion into non-first chunk}\mbox{}\par

  Now let's consider an insertion into any \emph{INSERTION} chunk. This happens when the key-value pair with a key greater than 20 needs to be stored in the queue. Generally, two possible situations might appear during the insertion into a non-first chunk.\par

  The first case happens when we are going to store an element in a not fully packed chunk. In this situation, the thread gets the current index of the first free position and stores the element directly into the chunk. After that, the insertion operation is finished.\par

  The second case is slightly more complicated, and appears when the current non-first chunk is full. In this situation, the CBPQ should be restructured by calling \textit{freezeChunk()} and \textit{freezeRecovery()} functions. These two function's behaviors are essentially the same as they are for insertion into the first chunk. The function \textit{freezeChunk()} calls \textit{freezeKeys()} function for every non-first chunk, in order to freeze all elements which are already stored in the chunk. The function \textit{freezeRecovery()} invokes \textit{split()} function, which splits the current full non-first chunk into two new half-full chunks containing lower-valued and higher-valued parts of keys, respectively. After CPBQ is restructured, the thread retries to store the new element into the non-first chunk again.\par

  As it happens in the case of insertion into the first chunk, once the new key-value pair is successfully added to the queue, the thread increases the index value using atomic F\&I instruction, and we can safely return.

  \paragraph{Deletion from the first chunk}\mbox{}\par
  This operation is supported only by the first chunk or any other chunk with state \emph{DELETION}.\par

  The deletion operation is straightforward. Each thread gets the frozen index of the current first chunk, which points right after the last deleted element and returns the current key-value pair. If the first chunk is currently empty, then CBPQ needs to be restructured to find another \emph{DELETION} chunk, which becomes the current first chunk. Once the queue is restructured, the thread attempts to remove the high-priority element again.\par

  Once the deletion is done, the thread increases the value of the frozen index using atomic F\&I instruction, and as in all previous cases, we can safely return.

  \paragraph{Worst-case bounds estimation}\mbox{}\par 

  According to the provided description of the CBPQ implementation, it is possible to notice that the most expensive operation of our queue is the restructuration process.\par

  Considering this fact, we can state that the worst case of insertion in CBPQ is a situation where all new elements are inserted only into the first chunk (as insertion into the first chunk requires the queue to be restructured every time).\par

  In the deletion operation, the worst case appears when all elements have been deleted from the current first chunk, and we need to execute the CBPQ restructure in order to get the key to be deleted from another \emph{DELETION} chunk.\newline\par

  This section gives only a bird's eye overview of how CPBQ works. Again, we refer you to the paper [1] for any specific details.

  \subsection{Project Structure}

  The project contains several directories: \textit{benchmark/} directory, which stores the script to run the benchmark and collect data for plots construction, \textit{plots/} and \textit{report/} directories for plots and report storage, respectively, and \textit{src/} directory, which contains all benchmark's and CPBQ's sources.\par

  Apart from that there are two files: \textit{Makefile}, which serves to build and run the benchmark, and \textit{README.md}, which contains project description.\par

  \textbf{Read README.md carefully before using any Makefile targets!}\par
  All project sources might be found in [4].

  \section{Performance Evaluation}
  The benchmark used for evaluation is a set of five tests, each of which runs the main CBPQ operations. Before each test, we fill our queue with 10000 elements to avoid running our benchmark with an empty queue. These elements contain randomly generated keys in range $1 \leqslant 100$ in order to destribute all items amongst chunks uniformly. For each test, we measure the running time that our program takes to perform the operations on the queue for the given number of threads.\par

  The first test shows\textbf{ mixed workload with 50\% of deletion operations}. During this test, we insert and remove 5000 key-value pairs into/from CBPQ. The results of this test are shown on \cref{fig:plot1}.\par

  The second test shows \textbf{mixed workload with 80\% of deletion operations}. During this test, we insert 2000 and remove 8000 key-value pairs into/from CBPQ. The results of this test are shown on \cref{fig:plot2}.\par

  The third test shows \textbf{mixed workload with 20\% of deletion operations}. During this test, we insert 8000 and remove 2000 key-value pairs into/from CBPQ. The results of this test are shown on \cref{fig:plot3}.\par

  The fourth test represents \textbf{deletion-only workload}. During this test, 10000 key-value pairs are removed from CBPQ. The results of this test are shown on \cref{fig:plot4}.\par

  The fifth test represents \textbf{insertion-only workload}. During this test, 10000 key-value pairs are inserted into CBPQ. The results of this test are shown on \cref{fig:plot5}.\par

  Also, we tested our queue with many more elements, but we decided to stop on 10000 elements due to time restrictions so that our benchmark doesn't run too long. In practice, the benchmark executes all tests for approximately 1 minute on the Nebula cluster.

  \begin{figure}[H]
    \centering
    \includegraphics{../plots/plot1.pdf}
    \caption{Mixed workload with 50\% of deletion operations.}
    \label{fig:plot1}
  \end{figure}

  \begin{figure}[H]
    \centering
    \includegraphics{../plots/plot2.pdf}
    \caption{Mixed workload with 80\% of deletion operations.}
    \label{fig:plot2}
  \end{figure}

  \begin{figure}[H]
    \centering
    \includegraphics{../plots/plot3.pdf}
    \caption{Mixed workload with 20\% of deletion operations.}
    \label{fig:plot3}
  \end{figure}

  \begin{figure}[H]
    \centering
    \includegraphics{../plots/plot4.pdf}
    \caption{Deletion-only workload.}
    \label{fig:plot4}
  \end{figure}

  \begin{figure}[H]
    \centering
    \includegraphics{../plots/plot5.pdf}
    \caption{Insertion-only workload.}
    \label{fig:plot5}
  \end{figure}

  \section{Conclusion}
  In this report, we presented a novel concurrent, linearizable, and lock-free design of the priority queue, called CBPQ, based on [1]. CBPQ cleverly combines the chunked linked list and the performance advantage of the F\&I atomic instructions.\par
  According to the benchmark results, as we can see from the generated plots, the scalability of CBPQ increases with an increasing number of \textit{Insert()} operations. So, the benchmark results are analyzed as follows.\par

  The best scalability was achieved for the Insertion-only workload. The mixed workloads with 20\%, 50\%, and 80\% of \textit{DeleteMin()} operations take second, third, and fourth places, respectively. Deletion-only workload barely has any speedup. That happens because, as mentioned before, deletion is a cheap operation, even for only one thread, and it is hard to get any speedup for a given number of elements stored in the queue.\par

  In conclusion, CBPQ is a quite sophisticated structure, and we assume that our implementation of CBPQ does not completely fits to all ideas described in [1]. Most likely, something was missed, and because of that, our queue doesn't scale as well as it might be. However, we believe that in terms of educational purposes, we achieved decent results and learned a lot of valuable things about multi-thread programming.

  \pagebreak

  \section*{References}
    \begin{enumerate}
      \item\parbox{0.9\textwidth}{Anastasia Braginsky, Nachshon Cohen, Erez Petrank: CBPQ: High-Performance Lock-Free Priority Queue. Euro-Par 2016: 460-474}
      \item\parbox{0.9\textwidth}{OpenMP 5.2 API Syntax Reference Guide: \url{https://www.openmp.org/wp-content/uploads/OpenMPRefCard-5-2-web.pdf}}
      \item\parbox{0.9\textwidth}{Built-in Functions for Memory Model Aware Atomic Operations: \url{https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html\#Built-in-Functions-for-Memory-Model-Aware-Atomic-Operations}}
      \item\parbox{0.9\textwidth}{Concurrent-Priority-Queue: \url{https://github.com/takeltez/Concurrent-Priority-Queue}}
    \end{enumerate}

\end{document}
