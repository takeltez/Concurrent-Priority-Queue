\documentclass{article}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{authblk}
\usepackage{amssymb}
\usepackage{float}
\usepackage{xurl}

\begin{document}

\title{Project in Advanced Multiprocessor Programming}
\author[1]{Aleksei Karasev - 12227646}
\author[2]{Mariana da Silva Barros - 12202389}
\affil[1]{MSc student of Computer Engineering, TU Wien}
\affil[2]{MSc student of Computer Engineering, TU Wien}
\maketitle

\section{Introduction}
Priority queues serve as an important basic tool in algorithmic design.
They are widely used in a variety of applications and systems, such as simulation systems, job scheduling (in computer systems), networking (e.g. routing and real-time bandwidth management), file compression, numerical computations, and more. With the proliferation of modern parallel platforms, the need for a highperformance concurrent implementation of the priority queue has become acute.\par

The basic structure of a priority queue (PQ) is a queue data structure, that stores values in a certain order depending on the priority. Therefore, to each element stored in this structure, there is also a priority associated, that can vary depending on the application. The abstract definition of a PQ provides a set of key-value pairs, where the key represents the priority.\par

A PQ supports two operations: \textit{insert} and \textit{deleteMin}. The \textit{insert()} method inserts a new key-value pair into the set in the appropriate position (the keys donâ€™t have to be unique), and the \textit{deleteMin()} method removes and returns the value associated with the lowest key (i.e., highest priority) in the set.\par

In this report we present the design of a high performance lock-free linearizable PQ called CBPQ, based on the paper [1].\par
In a nutshell, as described on [1], CBPQ combines the following ideas:

\begin{itemize}
  \item It is used a chunked linked-list as underlying data structure, which allows to search for a chunk for insertion operation more efficiently.
  \item For threads concurrency we apply synchronization primitives, such as critical sections and atomic operations (\textit{atomic or, atomic xor, atomic fetch and increment, atomic compare and swap}).
\end{itemize}

The more detailed description of how CBPQ works will be provided in next section.

\section{Overview}
\subsection{CBPQ Design}

As it has been previously mentioned, CBPQ is based on a chunked linked-list structure. In particular, the PQ contains three chunks to store values in the beginning. Each chunk has an associated state, which describes which operation is being performed, or which operations are supported at the moment.\par

The first chunk is structrured in a particular way, because it stores the key-value pairs with highest priority (key range $0 \leqslant 20$). Therefore, this is the only chunk which supports \textit{deleteMin} operations, and it doesn't permit direct insertion. In order to insert elements into this first chunk, we use an associated buffer, which will be further discussed below.\par

The remaining two chunks serve for insertion only, which is done directly in the chunk, without a buffer. The key ranges of second and third chunks are $21 \leqslant 40$ and $41 \leqslant 4294967295$, respectively.\par
Due to lack of space, we omit the concrete description of the chunk structure and its properties, which might be found in the paper our work is based on. [1]\par

Now, we would like to give a brief explanation of the \textit{insert} and \textit{deleteMin} operations usage, and take a look on several cases which might appear during queue exploitation.

\paragraph{Insertion into the first chunk}\mbox{}\par

Insertion into the first chunk may happen when its state is \emph{DELETION}, and we want to store a key-value pair with key range $0 \leqslant 20$.\par

Initially, the correct chunk for insertion is searched in the queue. Right after first chunk is found, \textit{insertToBuffer()} function is called in order to put the new element into the buffer. Inside this function, each thread checks whether the buffer was already allocated by one of previous threads or not. If it was, then the element is stored in the already existing buffer, otherwise the thread first allocates the buffer, and then it stores the new item into it.\par

Every time a new element is placed into the buffer, we need to restructure the CBPQ in order to merge the current first chunk with its buffer. First of all, the chunks are marked as \emph{FROZEN} in the \textit{freezeChunk()} function. Ny doing this, we signalize to all other threads that this chunk is already in use, so the othe threads don't try to use this chunk and cause a synchronization problem. Once the chunk is frozen, \textit{freezeRecovery()} function is called in order to restructure the CBPQ. In case of insertion into the first chunk, we execute \textit{mergeFirstChunk()} function, which merges the current first chunk with the buffer, and returns a pointer to the new first chunk (which is now the actual first chunk in our queue).\par

In the situation where the current first chunk is already full and doesn't have space for new elements from the buffer, several new \emph{DELETION} chunks are created. Also, there might be a case where it is impossible for a thread to put a new element into the buffer, due to the fact that the buffer is completely packed by other threads already. Then, the thread first restructures the queue, and then retries to store its element again.\par

Once the new key-value pair is successfully added into the first chunk, the thread increases the index using an atomic F\&I instruction, and we can safely return.

\paragraph{Insertion into non-first chunk}\mbox{}\par

Now let's consider an insertion into any \emph{INSERTION} chunk. This case happens when the key-value pair with a key greater than 20 needs to be stored into the queue. Generally, there are two possible situations which might appear during the insertion into a non-first chunk.\par

The first case happens when we are going to store an element into a not fully packed chunk. In this situation, the thread just gets the actual index of the first free position and stores the element directly into the chunk. After that, the insertion operation is finished.\par

The second case is a bit more complicated, and appears when the current non-first chunk is full, and the CBPQ should be restructured calling \textit{freezeChunk()} and \textit{freezeRecovery()} functions. These two functions' behaviors are essencially the same as for insertion into the first chunk. Function \textit{freezeChunk()} calls \textit{freezeKeys()} function for every non-first chunk, in order to freeze all elements which are already stored into the chunk. Function \textit{freezeRecovery()} invokes \textit{split()} function, which splits the current full non-first chunk into two new half-full chunks containing lower-valued and higher-valued parts of keys, respectivelly. After CPBQ is restructured, the thread retries to store the new element into the non-first chunk again.\par

As it happens in case of insertion into the first chunk, once the new key-value pair is successfully added to the queue, the thread increases the value of index using atomic F\&I instruction, and we can safely return.

\paragraph{Deletion from the first chunk}\mbox{}\par
This operation is supported only by the first chunk or any other chunk with state \emph{DELETION}.\par

The deletion operation is straightforward. Each thread just gets the frozen index of the current first chunk, which points right after the last deleted element and returns the actual key-value pair. If the first chunk is currently empty, then CBPQ needs to be restructured, in order to find another \emph{DELETION} chunk which becomes the current first chunk. Once the queue is restructured, the thread attempts to remove the high-priority element again.\par

Once deletion is done, the thread increases the value of frozen index using atomic F\&I instruction, and as in all previous cases we can safely return.
\pagebreak

\paragraph{Worst-case bounds estimation}\mbox{}\par 

According to the provided description of the CBPQ implementation, it is possible to notice that the most expensive operation of our queue is the restructuration process.\par

Considering this fact, we can state that the worst case of insertion in CBPQ is a situation where all new elements are inserted only into the first chunk (as insertion into the first chunk requires the queue to be restructured every time).\par

In the deletion operation, the worst case appears when all elements have been deleted from the current first chunk, and we need to execute the CBPQ restructure in order to get the key to be deleted from other \emph{DELETION} chunk.\newline\par

This section gives only a bird's eye overview of how CPBQ works. For any specific details we, again, refer you to the paper [1].

\subsection{Project Structure}

The project contains several directories: \textit{benchmark/} directory, which stores the script to run the benchmark and collect data for plots construction, \textit{plots/} and \textit{report/} directories for plots and report storage, respectively, and \textit{src/} directory, which contains all benchmark's and CPBQ's sources.\par

Apart from that there are two files: \textit{Makefile}, which serves to build and run the benchmark, and \textit{README.md}, which contains project description.\par

\textbf{Read README.md carefully before use any Makefile targets!}\par
All project's sources might be found in [4].

\section{Performance Evaluation}
The provided benchmark is a set of five tests, each of which runs the main CBPQ operations. Before each test, we fill our queue with 10.000 elements in order to not run our benchmark with an empty queue.\par

The first test shows\textbf{ mixed workload with 50\% of deletion operations}. During this test, we insert and remove 5000 key-value pairs into/from CBPQ. The results of this test are shown on \cref{fig:plot1}.\par

The second test shows \textbf{mixed workload with 80\% of deletion operations}. During this test, we insert 2000 and remove 8000 key-value pairs into/from CBPQ. The results of this test are shown on \cref{fig:plot2}.\par

The third test shows \textbf{mixed workload with 20\% of deletion operations}. During this test, we insert 8000 and remove 2000 key-value pairs into/from CBPQ. The results of this test are shown on \cref{fig:plot3}.\par

The fourth test represents \textbf{deletion-only workload}. During this test, 10000 key-value pairs are removed from CBPQ. The results of this test are shown on \cref{fig:plot4}.\par

The fifth test represents \textbf{insertion-only workload}. During this test, 10000 key-value pairs are inserted into CBPQ. The results of this test are shown on \cref{fig:plot5}.\par

Also, we would like to notice that we tested our queue with much more elements, but due to time restrictions, we decided to stop on 10000 elements so that our benchmark doesn't run too long. In pratcice, benchmark executes all tests for approximately 2 minutes on Nebula cluster.

\begin{figure}[H]
  \centering
  \includegraphics{../plots/plot1.pdf}
  \caption{Mixed workload with 50\% of deletion operations.}
  \label{fig:plot1}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics{../plots/plot2.pdf}
  \caption{Mixed workload with 80\% of deletion operations.}
  \label{fig:plot2}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics{../plots/plot3.pdf}
  \caption{Mixed workload with 20\% of deletion operations.}
  \label{fig:plot3}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics{../plots/plot4.pdf}
  \caption{Deletion-only workload.}
  \label{fig:plot4}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics{../plots/plot5.pdf}
  \caption{Insertion-only workload.}
  \label{fig:plot5}
\end{figure}

\section{Conclusion}
In this report we presented a novel concurrent, linearizable, and lock-free design of the priority queue, called CBPQ, based on [1]. CBPQ cleverly combines the chunked linked-list and the performance advantage of the F\&I atomic instruction.\par
According to the benchmark results, as we can see from the generated plots, scalability of CBPQ increases with increasing number of \textit{Insert()} operations. So, the benchamark results are analyzed as it follows.\par

The best scalability was achieved for Insertion-only workload. The mixed workloads with 20\%, 50\% and 80\% of \textit{DeleteMin()} operations take second, third and fourh places, respectively. Deletion-only workload barely has any speedup. That happens because, as already mentioned before, deletion is a cheap operation, even for only one thread, and it is hard to get any speedup for a given number of elements stored into the queue.\par

In conclusion, we would like to say that CBPQ is a quite sophisticated structure, and we assume that our implementation of CBPQ does completely fit to all ideas described in [1]. Most likely, something was missed, and maybe because of that our queue doesn't scale as well as it might be. However, we believe that in terms of educational purposes, we achieved decent results and learned a lot of valuable things about multi-threads programming.

\pagebreak
\section*{References}
\begin{enumerate}
\item{Anastasia Braginsky, Nachshon Cohen, Erez Petrank: CBPQ: High Performance Lock-Free Priority Queue. Euro-Par 2016: 460-474}
\item{OpenMP 5.2 API Syntax Reference Guide: \url{https://www.openmp.org/wp-content/uploads/OpenMPRefCard-5-2-web.pdf}}
\item{Built-in Functions for Memory Model Aware Atomic Operations: \url{https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html#Built-in-Functions-for-Memory-Model-Aware-Atomic-Operations}}
\item{Concurrent-Priority-Queue: \url{https://github.com/takeltez/Concurrent-Priority-Queue}}
\end{enumerate}
\end{document}
